{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bertimbau - CL (JL+)/GitHub.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hate speech detection with CLL"
      ],
      "metadata": {
        "id": "BMplmJmuXHU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inspired in codes provided by Chris McCormick and Nick Ryan"
      ],
      "metadata": {
        "id": "E4mKoME_Yui2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD DATA"
      ],
      "metadata": {
        "id": "NDgNVPnBlzm3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4wVPSUWwS2a"
      },
      "source": [
        "import pandas as pd\n",
        "df_full = #pd.read_csv()\n",
        "pt_df_train = #pd.read_csv()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdCVgvsnZVmO"
      },
      "source": [
        "#When using JL, CL/JL and CL/JL+ strategies, we add a part of the data in Target Language on initial training\n",
        "percentage = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtI9o_4-GXSb"
      },
      "source": [
        "amostra = pt_df_train.sample(frac=percentage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuzu1s2Gj1U0"
      },
      "source": [
        "amostraValid = amostra.sample(frac=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNXAIfiRj_fJ"
      },
      "source": [
        "amostra = amostra.drop(amostraValid.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ3muZuakUaS"
      },
      "source": [
        "amostraValidIt = df_full.sample(frac=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6Li8sEbkUaV"
      },
      "source": [
        "df_full = df_full.drop(amostraValidIt.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eeMSoVxuxND"
      },
      "source": [
        "df_full = df_full.append(amostra)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Loading BERTimbau tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ"
      },
      "source": [
        "# Tokenizing the sentences \n",
        "max_len = 128\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "labels = []\n",
        "\n",
        "for index, row in df_full.iterrows():  \n",
        "    text = row['translation']\n",
        "    encoded_dict = tokenizer.encode_plus(text, \n",
        "                                              max_length=max_len, \n",
        "                                              padding='max_length',\n",
        "                                              truncation=True, \n",
        "                                              return_tensors='pt')\n",
        "    \n",
        "  \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    labels.append(row['target'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "df_valid = amostraValid.append(amostraValidIt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFEP6pnLl9O-"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "max_len = 128\n",
        "\n",
        "labels_val = []\n",
        "input_ids_val = []\n",
        "attn_masks_val = []\n",
        "\n",
        "for index, row in df_valid.iterrows():\n",
        "\n",
        "\n",
        "    text = row['translation']\n",
        "    encoded_dict = tokenizer.encode_plus(text, \n",
        "                                              max_length=max_len, \n",
        "                                              padding='max_length',\n",
        "                                              truncation=True, \n",
        "                                              return_tensors='pt')\n",
        "\n",
        "\n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    attn_masks_val.append(encoded_dict['attention_mask'])\n",
        "    labels_val.append(row['target'])\n",
        "\n",
        "    \n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attn_masks_val = torch.cat(attn_masks_val, dim=0)\n",
        "labels_val = torch.tensor(labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vur4EGkyoE84"
      },
      "source": [
        "val_dataset = TensorDataset(input_ids_val, attn_masks_val, labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"neuralmind/bert-large-portuguese-cased\", \n",
        "    num_labels = 2, output_attentions = False, output_hidden_states = False,)\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-6, \n",
        "                  eps = 1e-8 \n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 3\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        " \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKA9QdXy6IO6"
      },
      "source": [
        "# Saving Model (executed when using CL, CL/JL or CL/JL+ strategies)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnXrsEyg6WM3"
      },
      "source": [
        "import os \n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "timestamp = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H%M')\n",
        "\n",
        "local_dir = './Model Save ' + timestamp + '/'\n",
        "\n",
        "if not os.path.exists(local_dir):\n",
        "    os.makedirs(local_dir)\n",
        "\n",
        "model.save_pretrained(local_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgpB0pw46WM5",
        "outputId": "92e2b180-e997-426a-fdbd-dd50d6db5335"
      },
      "source": [
        "import shutil\n",
        "#copy to gdrive\n",
        "gdrive_dir = #'/location'\n",
        "\n",
        "gdrive_dir = gdrive_dir + local_dir[2:]\n",
        "\n",
        "shutil.copytree(local_dir, gdrive_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying model save to ../content/drive/My Drive/Colab Notebooks/multi/Model Save 2022-02-03 2021/\n",
            "     config.json                      0.00 MB\n",
            "     pytorch_model.bin             1275.78 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt4oPaUP9jbN"
      },
      "source": [
        "# **Model Loading**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After we save the model, we then load the weights onto a new model, and then we start new fine tunings (executed when using CL, CL/JL and CL/JL+ strategies)"
      ],
      "metadata": {
        "id": "3w7n26pUQceW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXQGxBDWcQrw",
        "outputId": "2f462b2c-dc86-4884-fd97-c965192c1b09"
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda')\n",
        "desc = model.to(device)\n",
        "torch.cuda.empty_cache()\n",
        "gdrive_dir = #'/location'\n",
        "model = BertForSequenceClassification.from_pretrained(gdrive_dir, num_labels=2)\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model to GPU...\n",
            "  GPU: Tesla T4\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2w810bD50mE"
      },
      "source": [
        "# **ADDITIONAL FINE TUNINGS**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Executed when using CL/JL+ strategy"
      ],
      "metadata": {
        "id": "ekVZXgmYROYz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZhH_doGVAar"
      },
      "source": [
        "pt_df_train = pt_df_train.drop(amostra.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKsAzjVNbxSp"
      },
      "source": [
        "#determine the number of additional fine tunings\n",
        "NUM_FINE = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX9cn5az_869"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=NUM_FINE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uSZE7O6UO23"
      },
      "source": [
        "samples = skf.split(pt_df_train['text'], pt_df_train['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1QshSdic0zq"
      },
      "source": [
        "# Additional fine-tunings beginning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7BHcJL5c_Ud"
      },
      "source": [
        "ITERATION_NUMBER = 1\n",
        "generator =next(samples)\n",
        "kfold = list(generator)\n",
        "\n",
        "amostraTrainPtX = pt_df_train.iloc[kfold[0],:]\n",
        "amostraTestPtx = pt_df_train.iloc[kfold[1],:]\n",
        "\n",
        "amostraTreinoPt = amostraTrainPtX\n",
        "amostraTestePt =  amostraTestPtx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EmkiC8t54fU"
      },
      "source": [
        "import torch\n",
        "\n",
        "#tokenizing the training dataset\n",
        "max_len = 128\n",
        "\n",
        "labels = []\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "\n",
        "for index, row in amostraTreinoPt.iterrows():\n",
        "\n",
        "    text = row['text']\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(text, \n",
        "                                              max_length=max_len, \n",
        "                                              padding='max_length',\n",
        "                                              truncation=True, \n",
        "                                              return_tensors='pt')\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    labels.append(row['target'])\n",
        "\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXO0Hon054fh"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQWXpWI54fn"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhIzVlQs6Esb"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-6, \n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfnxH-GtNSyD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx7MENap6Esb"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 3\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-NazFnUMGcB"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "     \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "      \n",
        "        model.zero_grad()        \n",
        "\n",
        "       \n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "       \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "      \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "      \n",
        "        with torch.no_grad():        \n",
        "\n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_0AizISMGcS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df_stats\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh"
      },
      "source": [
        "import torch\n",
        "\n",
        "labels_ar = []\n",
        "input_ids_ar = []\n",
        "attn_masks_ar = []\n",
        "\n",
        "print('Encoding test examples...')\n",
        "\n",
        "for index, ex in amostraTestePt.iterrows():\n",
        "\n",
        "    text = ex['text']\n",
        "    encoded_dict = tokenizer.encode_plus(text, \n",
        "                                              max_length=max_len, \n",
        "                                              padding='max_length',\n",
        "                                              truncation=True, \n",
        "                                              return_tensors='pt')\n",
        "\n",
        "    input_ids_ar.append(encoded_dict['input_ids'])\n",
        "    attn_masks_ar.append(encoded_dict['attention_mask'])\n",
        "    labels_ar.append(ex['target'])\n",
        "    \n",
        "input_ids_ar = torch.cat(input_ids_ar, dim=0)\n",
        "attn_masks_ar = torch.cat(attn_masks_ar, dim=0)\n",
        "\n",
        "labels_ar = torch.tensor(labels_ar)\n",
        "\n",
        "print('   DONE. {:,} examples.'.format(len(labels_ar)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "## Evaluating the model with data from target language\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6"
      },
      "source": [
        "prediction_dataset = TensorDataset(input_ids_ar, attn_masks_ar, labels_ar)\n",
        "\n",
        "prediction_dataloader = DataLoader(prediction_dataset, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx"
      },
      "source": [
        "#evaluating model\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "count = 0\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    \n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs"
      },
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "predicted_labels = np.argmax(flat_predictions, axis=1).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQdLXDMZQXqa"
      },
      "source": [
        "#printing f1 weighted\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(flat_true_labels, predicted_labels, average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSVJOWTiqMS6"
      },
      "source": [
        " #printing classification report\n",
        " from sklearn.metrics import classification_report\n",
        " print(classification_report(flat_true_labels, predicted_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional fine-tunings ending"
      ],
      "metadata": {
        "id": "it5eLFSRWAbP"
      }
    }
  ]
}