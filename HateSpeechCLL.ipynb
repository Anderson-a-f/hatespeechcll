{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bertimbau - CL (JL+)/GitHub.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13e269e-5ed2-4e72-9676-d9857e0caa60"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD DATA"
      ],
      "metadata": {
        "id": "NDgNVPnBlzm3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4wVPSUWwS2a"
      },
      "source": [
        "import pandas as pd\n",
        "df_full = #pd.read_csv()\n",
        "pt_df_train = #pd.read_csv()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdCVgvsnZVmO"
      },
      "source": [
        "#When using JL, CL/JL and CL/JL+ strategies, we add a part of the data in Target Language on initial training\n",
        "percentage = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtI9o_4-GXSb"
      },
      "source": [
        "amostra = pt_df_train.sample(frac=percentage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuzu1s2Gj1U0"
      },
      "source": [
        "amostraValid = amostra.sample(frac=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNXAIfiRj_fJ"
      },
      "source": [
        "amostra = amostra.drop(amostraValid.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ3muZuakUaS"
      },
      "source": [
        "amostraValidIt = df_full.sample(frac=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6Li8sEbkUaV"
      },
      "source": [
        "df_full = df_full.drop(amostraValidIt.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eeMSoVxuxND"
      },
      "source": [
        "df_full = df_full.append(amostra)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Loading BERTimbau tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ"
      },
      "source": [
        "# Tokenizing the sentences and map the tokens to word IDs.\n",
        "max_len = 128\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "labels = []\n",
        "\n",
        "for index, row in df_full.iterrows():  \n",
        "    text = row['translation']\n",
        "    encoded_dict = tokenizer.encode_plus(text, \n",
        "                                              max_length=max_len, \n",
        "                                              padding='max_length',\n",
        "                                              truncation=True, \n",
        "                                              return_tensors='pt')\n",
        "    \n",
        "  \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    labels.append(row['target'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "df_valid = amostraValid.append(amostraValidIt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFEP6pnLl9O-",
        "outputId": "8760fc02-b670-4d24-edac-a123c69a10b2"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "max_len = 128\n",
        "\n",
        "labels_val = []\n",
        "input_ids_val = []\n",
        "attn_masks_val = []\n",
        "\n",
        "for index, row in df_valid.iterrows():\n",
        "\n",
        "\n",
        "    text = row['translation']\n",
        "    encoded_dict = tokenizer.encode_plus(text, \n",
        "                                              max_length=max_len, \n",
        "                                              padding='max_length',\n",
        "                                              truncation=True, \n",
        "                                              return_tensors='pt')\n",
        "\n",
        "\n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    attn_masks_val.append(encoded_dict['attention_mask'])\n",
        "    labels_val.append(row['target'])\n",
        "\n",
        "    \n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attn_masks_val = torch.cat(attn_masks_val, dim=0)\n",
        "labels_val = torch.tensor(labels_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding all examples...\n",
            "   DONE. 445 examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vur4EGkyoE84"
      },
      "source": [
        "val_dataset = TensorDataset(input_ids_val, attn_masks_val, labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"neuralmind/bert-large-portuguese-cased\", \n",
        "    num_labels = 2, output_attentions = False, output_hidden_states = False,)\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-6, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 3\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        " \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKA9QdXy6IO6"
      },
      "source": [
        "# Saving Model (executed when using CL, CL/JL or CL/JL+ strategies)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnXrsEyg6WM3"
      },
      "source": [
        "import os \n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "timestamp = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H%M')\n",
        "\n",
        "local_dir = './Model Save ' + timestamp + '/'\n",
        "\n",
        "if not os.path.exists(local_dir):\n",
        "    os.makedirs(local_dir)\n",
        "\n",
        "model.save_pretrained(local_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgpB0pw46WM5",
        "outputId": "92e2b180-e997-426a-fdbd-dd50d6db5335"
      },
      "source": [
        "import shutil\n",
        "#copy to gdrive\n",
        "gdrive_dir = #'/location'\n",
        "\n",
        "gdrive_dir = gdrive_dir + local_dir[2:]\n",
        "\n",
        "shutil.copytree(local_dir, gdrive_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying model save to ../content/drive/My Drive/Colab Notebooks/multi/Model Save 2022-02-03 2021/\n",
            "     config.json                      0.00 MB\n",
            "     pytorch_model.bin             1275.78 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt4oPaUP9jbN"
      },
      "source": [
        "# **Model Loading**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After we save the model, we then load the weights onto a new model, and then we start new fine tunings (executed when using CL, CL/JL and CL/JL+ strategies)"
      ],
      "metadata": {
        "id": "3w7n26pUQceW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXQGxBDWcQrw",
        "outputId": "2f462b2c-dc86-4884-fd97-c965192c1b09"
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda')\n",
        "desc = model.to(device)\n",
        "torch.cuda.empty_cache()\n",
        "gdrive_dir = #'/location'\n",
        "model = BertForSequenceClassification.from_pretrained(gdrive_dir, num_labels=2)\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model to GPU...\n",
            "  GPU: Tesla T4\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2w810bD50mE"
      },
      "source": [
        "# **ADDITIONAL FINE TUNINGS**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Executed when using CL/JL+ strategy"
      ],
      "metadata": {
        "id": "ekVZXgmYROYz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZhH_doGVAar"
      },
      "source": [
        "pt_df_train = pt_df_train.drop(amostra.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "PTQYC1tdVAas",
        "outputId": "3d61def9-2844-4416-e872-08abc3e1ef25"
      },
      "source": [
        "pt_df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bca696b9-b0ee-4860-adff-48de0b614255\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yes</td>\n",
              "      <td>'Votaram no PEZAO Agora tomem no CZAO'</td>\n",
              "      <td>1</td>\n",
              "      <td>you voted for the pezao now take the czao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>no</td>\n",
              "      <td>'cuidado com a poupanca pessoal Lembram o que ...</td>\n",
              "      <td>0</td>\n",
              "      <td>be careful with personal savings remember what...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no</td>\n",
              "      <td>'Sabe o que eu acho engracado os nossos govern...</td>\n",
              "      <td>0</td>\n",
              "      <td>You know what I find funny, our rulers don't t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yes</td>\n",
              "      <td>'os cariocas tem o que merecem um pessoal que ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Cariocas have what they deserve, people who on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no</td>\n",
              "      <td>'Podiam retirar dos lucros dos bancos '</td>\n",
              "      <td>0</td>\n",
              "      <td>could withdraw from bank profits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1245</th>\n",
              "      <td>yes</td>\n",
              "      <td>'LIXO DO CRL'</td>\n",
              "      <td>1</td>\n",
              "      <td>crl garbage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1246</th>\n",
              "      <td>yes</td>\n",
              "      <td>'ela esta fazendo isso para aparecer Nao e gay...</td>\n",
              "      <td>1</td>\n",
              "      <td>she's doing this to appear she's not gay at al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1247</th>\n",
              "      <td>yes</td>\n",
              "      <td>'Volta pra jaula sua macaca vou pegar meu xico...</td>\n",
              "      <td>1</td>\n",
              "      <td>go back to the cage you monkey I'm going to ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1248</th>\n",
              "      <td>yes</td>\n",
              "      <td>'Achei que a macaca vivia apenas na floresta o...</td>\n",
              "      <td>1</td>\n",
              "      <td>I thought the monkey lived only in the forest ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249</th>\n",
              "      <td>yes</td>\n",
              "      <td>'Espera essa neve derreter e usa ela pra lavar...</td>\n",
              "      <td>1</td>\n",
              "      <td>wait for this snow to melt and use it to wash ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1050 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bca696b9-b0ee-4860-adff-48de0b614255')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bca696b9-b0ee-4860-adff-48de0b614255 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bca696b9-b0ee-4860-adff-48de0b614255');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     label  ...                                        translation\n",
              "0      yes  ...          you voted for the pezao now take the czao\n",
              "1       no  ...  be careful with personal savings remember what...\n",
              "2       no  ...  You know what I find funny, our rulers don't t...\n",
              "3      yes  ...  Cariocas have what they deserve, people who on...\n",
              "4       no  ...                   could withdraw from bank profits\n",
              "...    ...  ...                                                ...\n",
              "1245   yes  ...                                        crl garbage\n",
              "1246   yes  ...  she's doing this to appear she's not gay at al...\n",
              "1247   yes  ...  go back to the cage you monkey I'm going to ge...\n",
              "1248   yes  ...  I thought the monkey lived only in the forest ...\n",
              "1249   yes  ...  wait for this snow to melt and use it to wash ...\n",
              "\n",
              "[1050 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKsAzjVNbxSp"
      },
      "source": [
        "#determine the number of additional fine tunings\n",
        "NUM_FINE = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX9cn5az_869"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=NUM_FINE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uSZE7O6UO23"
      },
      "source": [
        "samples = skf.split(pt_df_train['text'], pt_df_train['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1QshSdic0zq"
      },
      "source": [
        "# Additional fine-tunings beginning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7BHcJL5c_Ud"
      },
      "source": [
        "ITERATION_NUMBER = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3jcwGEEN-HN"
      },
      "source": [
        "generator =next(samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YGKVyIMOE6i"
      },
      "source": [
        "kfold = list(generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpKwDeqpGv8a"
      },
      "source": [
        "amostraTrainPtX = pt_df_train.iloc[kfold[0],:]\n",
        "amostraTestPtx = pt_df_train.iloc[kfold[1],:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdbsRKR2GTKE"
      },
      "source": [
        "amostraTestPtx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkqNFfTTdGLn"
      },
      "source": [
        "amostraTreinoPt = amostraTrainPtX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejZQWOeG0UaU"
      },
      "source": [
        "amostraTestePt =  amostraTestPtx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EmkiC8t54fU",
        "outputId": "bc37c297-0d22-4d7d-f243-e264434c5cae"
      },
      "source": [
        "import torch\n",
        "\n",
        "#tokenizing the training dataset\n",
        "max_len = 128\n",
        "\n",
        "labels = []\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "\n",
        "for index, row in amostraTreinoPt.iterrows():\n",
        "\n",
        "    text = row['text']\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(text, \n",
        "                                              max_length=max_len, \n",
        "                                              padding='max_length',\n",
        "                                              truncation=True, \n",
        "                                              return_tensors='pt')\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    labels.append(row['target'])\n",
        "\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding all examples...\n",
            "   DONE. 840 examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXO0Hon054fh"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQWXpWI54fn"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhIzVlQs6Esb"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-6, \n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfnxH-GtNSyD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx7MENap6Esb"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 3\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-NazFnUMGcB",
        "outputId": "a01669ac-bb33-4afc-9e72-97b7d4167812"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "     \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "      \n",
        "        model.zero_grad()        \n",
        "\n",
        "       \n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "       \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "      \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "      \n",
        "        with torch.no_grad():        \n",
        "\n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     42.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.31\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     42.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:00:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.23\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     42.    Elapsed: 0:00:45.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:00:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.20\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:02:35 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_0AizISMGcS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df_stats\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### 5.1. Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2dfe09-d45f-4bbb-fa29-e298063ef5db"
      },
      "source": [
        "import torch\n",
        "\n",
        "labels_ar = []\n",
        "input_ids_ar = []\n",
        "attn_masks_ar = []\n",
        "\n",
        "print('Encoding test examples...')\n",
        "\n",
        "for index, ex in amostraTestePt.iterrows():\n",
        "\n",
        "    text = ex['text']\n",
        "    encoded_dict = tokenizer.encode_plus(text, \n",
        "                                              max_length=max_len, \n",
        "                                              padding='max_length',\n",
        "                                              truncation=True, \n",
        "                                              return_tensors='pt')\n",
        "\n",
        "    input_ids_ar.append(encoded_dict['input_ids'])\n",
        "    attn_masks_ar.append(encoded_dict['attention_mask'])\n",
        "    labels_ar.append(ex['target'])\n",
        "    \n",
        "input_ids_ar = torch.cat(input_ids_ar, dim=0)\n",
        "attn_masks_ar = torch.cat(attn_masks_ar, dim=0)\n",
        "\n",
        "labels_ar = torch.tensor(labels_ar)\n",
        "\n",
        "print('   DONE. {:,} examples.'.format(len(labels_ar)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding test examples...\n",
            "   DONE. 210 examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "## Evaluating the model with data from target language\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6"
      },
      "source": [
        "prediction_dataset = TensorDataset(input_ids_ar, attn_masks_ar, labels_ar)\n",
        "\n",
        "prediction_dataloader = DataLoader(prediction_dataset, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9318848-1499-48f7-b748-c79c8e8a47f8"
      },
      "source": [
        "#evaluating model\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "count = 0\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    \n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 210 test examples...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs"
      },
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "predicted_labels = np.argmax(flat_predictions, axis=1).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQdLXDMZQXqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7619170-568f-4538-a122-1d54e928c068"
      },
      "source": [
        "#printing f1 weighted\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(flat_true_labels, predicted_labels, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666060745709483"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSVJOWTiqMS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30f07d4-725c-40c0-b021-7acba051f5c5"
      },
      "source": [
        " #printing classification report\n",
        " from sklearn.metrics import classification_report\n",
        " print(classification_report(flat_true_labels, predicted_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       140\n",
            "           1       0.96      0.94      0.95        70\n",
            "\n",
            "    accuracy                           0.97       210\n",
            "   macro avg       0.96      0.96      0.96       210\n",
            "weighted avg       0.97      0.97      0.97       210\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional fine-tunings ending"
      ],
      "metadata": {
        "id": "it5eLFSRWAbP"
      }
    }
  ]
}